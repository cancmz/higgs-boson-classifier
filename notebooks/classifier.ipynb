{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# HiggsML Classifier – CERN Open Data Project\n",
    "\n",
    "This notebook implements a binary classification model to separate signal and background events using the Higgs Boson Challenge dataset.\n",
    "\n",
    "Author: Ahmet Can Çömez"
   ],
   "id": "6124abe5d72c1a2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Importing Dependencies\n",
    "\n",
    "This cell loads all required libraries for data handling, preprocessing, model training, evaluation, and persistence:\n",
    "\n",
    "- `pandas`: for data manipulation and numerical operations\n",
    "- `matplotlib.pyplot`, `seaborn`: for plotting and visualization\n",
    "- `scikit-learn`: for preprocessing, model building, and evaluation\n",
    "- `joblib`: to save the trained model\n",
    "- `os`: for handling file paths\n",
    "\n"
   ],
   "id": "1ef0323e702a374d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score"
   ],
   "id": "66ee6b20cb005a77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "The dataset is loaded from a local CSV file.\n",
    "We first inspect the shape of the data to understand the number of samples and features, and then display the first few rows using `head()` to preview the structure.\n"
   ],
   "id": "67dca81f718bcf7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "training_path = os.path.join(project_root, \"data\", \"training.csv\")\n",
    "df = pd.read_csv(training_path)\n",
    "df.head()"
   ],
   "id": "abdd6be753521c16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Target Variable Encoding\n",
    "\n",
    "The categorical target column `Label` is converted to binary numerical values:\n",
    "- `'s'` (signal) → 1\n",
    "- `'b'` (background) → 0\n",
    "\n",
    "This transformation is required for compatibility with machine learning algorithms.\n",
    "The updated distribution is reviewed to verify label encoding and assess class balance.\n"
   ],
   "id": "36e793fc088eba08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['Label'] = df['Label'].map({'s': 1, 'b': 0})",
   "id": "e16f6df20309fd15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataset Overview\n",
    "\n",
    "A concise summary of the dataset is obtained using `df.info()`.\n",
    "This includes column data types, non-null counts, and memory usage.\n",
    "The output is useful for detecting missing values and verifying dataset structure prior to preprocessing.\n"
   ],
   "id": "c89b06a43b612a0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.info()",
   "id": "5ce364be782a2c43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Visualizing Class Distribution\n",
    "\n",
    "This count plot displays the distribution of the target classes:\n",
    "Signal (`1`) and Background (`0`).\n",
    "It helps identify any class imbalance that may affect model performance.\n"
   ],
   "id": "58f10b47f5e88b44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.countplot(x='Label', data=df)\n",
    "plt.title(\"Signal (1) vs Background (0) Distribution\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "165cac63e78a071a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature and Target Definition\n",
    "\n",
    "The dataset is split into input features (`X`) and target labels (`Y`).\n",
    "The `Label`, `Weight`, and `EventId` columns are excluded from the feature matrix as they are either target indicators or metadata.\n",
    "This step structures the data appropriately for supervised learning.\n"
   ],
   "id": "dd26eb232d47df14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = df.drop(['Label', 'Weight', 'EventId'], axis=1)\n",
    "Y = df['Label']"
   ],
   "id": "516da8a9f1abafb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train-Test Split and Feature Scaling\n",
    "\n",
    "The dataset is divided into training and testing subsets using an 80-20 split.\n",
    "Feature standardization is then applied using `StandardScaler`, transforming the data to have zero mean and unit variance.\n",
    "This preprocessing step is essential for optimizing the performance and stability of many machine learning algorithms, including gradient boosting.\n"
   ],
   "id": "8474563d47fc79a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "da468353102f199f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosting Classifier Training\n",
    "\n",
    "A `GradientBoostingClassifier` is instantiated with the following hyperparameters:\n",
    "- `learning_rate = 0.1`\n",
    "- `max_depth = 5`\n",
    "- `n_estimators = 200`\n",
    "- `subsample = 0.8`\n",
    "\n",
    "The model is fitted on the standardized training data.\n",
    "After training, class predictions (`y_pred`) and predicted probabilities (`y_score`) are computed on the test set for subsequent evaluation.\n"
   ],
   "id": "1219b1d4c3aeb0eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = GradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    n_estimators=200,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, Y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_score = model.predict_proba(X_test_scaled)[:, 1]"
   ],
   "id": "75e8b8f3817b1062",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ROC Curve and AUC Score Evaluation\n",
    "\n",
    "The Receiver Operating Characteristic (ROC) curve is generated to assess the model's classification performance.\n",
    "The Area Under the Curve (AUC) is calculated to quantify the classifier's ability to distinguish between signal and background classes.\n",
    "AUC values closer to 1.0 indicate strong predictive performance.\n"
   ],
   "id": "3703790575100ad2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fpr, tpr, thresholds = roc_curve(Y_test, y_score)\n",
    "auc_score = roc_auc_score(Y_test, y_score)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "8258e008c77b76a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Confusion Matrix and Accuracy Score\n",
    "\n",
    "The confusion matrix is computed to provide a detailed breakdown of prediction results, showing true positives, false positives, true negatives, and false negatives.\n",
    "The accuracy score is also calculated to measure the overall proportion of correctly classified samples.\n",
    "This evaluation helps in understanding the model’s performance beyond a single metric.\n"
   ],
   "id": "d4385d8b279ff1d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Background (0)\", \"Signal (1)\"])\n",
    "disp.plot(cmap='Blues')\n",
    "\n",
    "acc = accuracy_score(Y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n"
   ],
   "id": "f16e7e9a1cdbbaf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Saving the Trained Model\n",
    "\n",
    "The trained `GradientBoostingClassifier` is serialized and saved using the `joblib` library.\n",
    "This allows the model to be reloaded later for inference or integration into other systems without retraining.\n"
   ],
   "id": "edd0f5a3a535a717"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "model_path = os.path.join(project_root, \"models\", \"higgs_classifier.joblib\")\n",
    "print(f\"Saving model to {model_path}\")\n",
    "joblib.dump(model, model_path)"
   ],
   "id": "93c5cce189a6be7a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
